name: Build llama-server.exe for Windows 7

on:
  push:
    branches: [ main ]
  workflow_dispatch:

jobs:
  build:
    runs-on: windows-2022

    steps:
    # –®–∞–≥ 1: –ö–ª–æ–Ω–∏—Ä—É–µ–º –í–ê–® —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π (–≥–¥–µ –ª–µ–∂–∏—Ç patches/)
    - name: Checkout patches repo
      uses: actions/checkout@v4
      with:
        repository: Alex-489/build-llama-server
        path: build-repo
        token: ${{ secrets.GITHUB_TOKEN }}  # üîë –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ!

    # –®–∞–≥ 2: –ö–ª–æ–Ω–∏—Ä—É–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ–µ–∫—Ç llama.cpp
    - name: Checkout llama.cpp
      uses: actions/checkout@v4
      with:
        repository: ggerganov/llama.cpp
        submodules: recursive

    # –®–∞–≥ 3: –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º MinGW-w64 (gcc 11.2.0) –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å Win7
    - name: Install winlibs MinGW-w64 (gcc 11.2.0)
      run: |
        Invoke-WebRequest -Uri https://github.com/brechtsanders/winlibs_mingw/releases/download/11.2.0-12.0.1-9.0.0-r1/winlibs-x86_64-posix-seh-gcc-11.2.0-mingw-w64-9.0.0-r1.7z -OutFile mingw.7z
        choco install 7zip -y
        7z x mingw.7z -oC:\mingw64
        echo "C:\mingw64\bin" >> $env:GITHUB_PATH

    # –®–∞–≥ 4: –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º CMake
    - name: Install CMake
      run: |
        Invoke-WebRequest -Uri https://github.com/Kitware/CMake/releases/download/v3.24.3/cmake-3.24.3-windows-x86_64.zip -OutFile cmake.zip
        Expand-Archive cmake.zip -DestinationPath C:\
        echo "C:\cmake-3.24.3-windows-x86_64\bin" >> $env:GITHUB_PATH

    # –®–∞–≥ 5: –ü–æ–¥–º–µ–Ω—è–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–π —Ñ–∞–π–ª ggml-cpu.c
    - name: Replace ggml-cpu.c with Win7-compatible version
      run: |
        if (Test-Path "build-repo/patches/ggml-cpu.c.patched") {
            Copy-Item build-repo/patches/ggml-cpu.c.patched ggml/src/ggml-cpu/ggml-cpu.c -Force
            Write-Host "‚úÖ –§–∞–π–ª ggml-cpu.c —É—Å–ø–µ—à–Ω–æ –∑–∞–º–µ–Ω—ë–Ω"
        } else {
            Write-Error "‚ùå –û—à–∏–±–∫–∞: —Ñ–∞–π–ª build-repo/patches/ggml-cpu.c.patched –Ω–µ –Ω–∞–π–¥–µ–Ω!"
            exit 1
        }

    # –®–∞–≥ 6: –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
    - name: Verify tools
      run: |
        gcc --version
        mingw32-make --version
        cmake --version

    # –®–∞–≥ 7: –°–æ–±–∏—Ä–∞–µ–º —Å–µ—Ä–≤–µ—Ä
    - name: Build llama-server
      shell: cmd
      run: |
        mkdir build
        cd build
        cmake .. ^
          -DCMAKE_BUILD_TYPE=Release ^
          -DGGML_BUILD_SERVER=ON ^
          -DCMAKE_SYSTEM_VERSION=6.1 ^
          -D_WIN32_WINNT=0x0601 ^
          -D__MINGW_USE_VC2005_COMPAT=ON ^
          -DGGML_CPU_HAS_SSE3=ON ^
          -DGGML_CPU_HAS_AVX=OFF ^
          -DGGML_CPU_HAS_AVX2=OFF ^
          -DLLAMA_CURL=OFF ^
          -DCMAKE_EXE_LINKER_FLAGS="-static -static-libgcc -static-libstdc++" ^
          -G "MinGW Makefiles"
        mingw32-make -C . -j4 llama-server

    # –®–∞–≥ 8: –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    - name: Upload Artifact
      uses: actions/upload-artifact@v4
      with:
        name: llama-server-win7-static.exe
        path: ./build/bin/llama-server.exe
