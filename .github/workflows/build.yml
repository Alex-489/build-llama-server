name: Build llama-server.exe for Windows 7

on:
  push:
    branches: [ main ]
  workflow_dispatch:

jobs:
  build:
    runs-on: windows-latest

    steps:
    - name: Checkout llama.cpp
      uses: actions/checkout@v4
      with:
        repository: ggerganov/llama.cpp
        submodules: recursive

    - name: Install dependencies
      run: |
        choco install cmake mingw -y
        $env:Path += ";C:\tools\mingw64\bin"
        [Environment]::SetEnvironmentVariable("Path", $env:Path, "Machine")

    - name: Verify tools
      run: |
        cmake --version
        gcc --version
        mingw32-make --version

    - name: Build llama-server
      run: |
        mkdir build
        cd build
        cmake .. ^
          -DCMAKE_BUILD_TYPE=Release ^
          -DGGML_BUILD_SERVER=ON ^
          -DCMAKE_SYSTEM_VERSION=6.1 ^
          -D_WIN32_WINNT=0x0601 ^
          -D__MINGW_USE_VC2005_COMPAT=ON ^
          -DGGML_CPU_HAS_SSE3=ON ^
          -DGGML_CPU_HAS_AVX=OFF ^
          -DGGML_CPU_HAS_AVX2=OFF ^
          -G "MinGW Makefiles"
        mingw32-make -C . -j4 llama-server

    - name: Upload Artifact
      uses: actions/upload-artifact@v4
      with:
        name: llama-server-win7.exe
        path: ./build/bin/llama-server.exe
