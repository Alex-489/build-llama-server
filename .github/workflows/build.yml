name: Build llama-server.exe for Windows 7

on:
  push:
    branches: [ main ]
  workflow_dispatch:

jobs:
  build:
    runs-on: windows-2022

    steps:
    - name: Checkout llama.cpp
      uses: actions/checkout@v4
      with:
        repository: ggerganov/llama.cpp
        path: llama-repo
        submodules: recursive

    - name: Install winlibs MinGW-w64 (gcc 11.2.0)
      run: |
        Invoke-WebRequest -Uri https://github.com/brechtsanders/winlibs_mingw/releases/download/11.2.0-12.0.1-9.0.0-r1/winlibs-x86_64-posix-seh-gcc-11.2.0-mingw-w64-9.0.0-r1.7z -OutFile mingw.7z
        choco install 7zip -y
        7z x mingw.7z -oC:\mingw64
        echo "C:\mingw64\bin" >> $env:GITHUB_PATH

    - name: Install CMake
      run: |
        Invoke-WebRequest -Uri https://github.com/Kitware/CMake/releases/download/v3.24.3/cmake-3.24.3-windows-x86_64.zip -OutFile cmake.zip
        Expand-Archive cmake.zip -DestinationPath C:\
        echo "C:\cmake-3.24.3-windows-x86_64\bin" >> $env:GITHUB_PATH

    - name: Patch ggml-cpu.c for Windows 7 compatibility
      run: |
        $file = "llama-repo/ggml/src/ggml-cpu/ggml-cpu.c"
        if (Test-Path $file) {
            $content = Get-Content $file -Raw
            # Добавляем определение Windows 7 в начало файла
            $patched = "#ifndef _WIN32_WINNT`n#define _WIN32_WINNT 0x0601 // Windows 7`n#endif`n`n" + $content
            # Просто закомментируем ВСЕ проблемные строки
            $patched = $patched -replace 'THREAD_POWER_THROTTLING_STATE', '// THREAD_POWER_THROTTLING_STATE'
            $patched = $patched -replace 'THREAD_POWER_THROTTLING_CURRENT_VERSION', '// THREAD_POWER_THROTTLING_CURRENT_VERSION'
            $patched = $patched -replace 'THREAD_POWER_THROTTLING_EXECUTION_SPEED', '// THREAD_POWER_THROTTLING_EXECUTION_SPEED'
            $patched = $patched -replace 'SetThreadInformation\(hThread, ThreadPowerThrottling, &t, sizeof\(t\)\);', '// SetThreadInformation(hThread, ThreadPowerThrottling, &t, sizeof(t));'
            $patched = $patched -replace 'ZeroMemory\(&t, sizeof\(t\)\);', '// ZeroMemory(&t, sizeof(t));'
            Set-Content $file $patched -Encoding UTF8
            Write-Host "✅ Файл $file успешно патчен"
        } else {
            Write-Error "❌ Ошибка: файл $file не найден!"
            exit 1
        }

    - name: Build llama-server
      shell: cmd
      run: |
        REM Переходим в папку llama-repo
        cd llama-repo
        REM Создаем build-директорию
        mkdir build
        cd build
        REM Запускаем CMake из правильной директории
        cmake .. ^
          -G "MinGW Makefiles" ^
          -DCMAKE_BUILD_TYPE=Release ^
          -DGGML_BUILD_SERVER=ON ^
          -DCMAKE_SYSTEM_VERSION=6.1 ^
          -D_WIN32_WINNT=0x0601 ^
          -D__MINGW_USE_VC2005_COMPAT=ON ^
          -DGGML_CPU_HAS_SSE3=ON ^
          -DGGML_CPU_HAS_AVX=OFF ^
          -DGGML_CPU_HAS_AVX2=OFF ^
          -DLLAMA_CURL=OFF ^
          -DCMAKE_EXE_LINKER_FLAGS="-static -static-libgcc -static-libstdc++"
        mingw32-make -C . -j4 llama-server

    - name: Upload Artifact
      uses: actions/upload-artifact@v4
      with:
        name: llama-server-win7-static.exe
        path: ./llama-repo/build/bin/llama-server.exe
